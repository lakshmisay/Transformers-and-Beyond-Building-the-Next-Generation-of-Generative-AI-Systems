{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82625b5f",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 1: Foundations of Generative AI\n",
    "\n",
    "This notebook demonstrates the key foundational concepts in Generative AI through hands-on examples using models such as GPT-2, Variational Autoencoders (VAEs), and Generative Adversarial Networks (GANs).\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand the difference between traditional and generative AI\n",
    "- Explore and implement Variational Autoencoders (VAEs)\n",
    "- Train a simple Generative Adversarial Network (GAN)\n",
    "- Use a pretrained Transformer for text generation\n",
    "- Apply decoding strategies: Greedy, Top-k, Top-p sampling\n",
    "- Evaluate generative models using metrics like BLEU, ROUGE, FID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eb023e",
   "metadata": {},
   "source": [
    "\n",
    "## Traditional AI vs Generative AI\n",
    "\n",
    "| Feature               | Traditional AI           | Generative AI                     |\n",
    "|-----------------------|---------------------------|----------------------------------|\n",
    "| Objective             | Classification, Prediction | Generation of new content       |\n",
    "| Output Type           | Labels, decisions         | Text, images, audio, code        |\n",
    "| Techniques            | SVM, Decision Trees, CNN  | VAE, GAN, Transformers           |\n",
    "| Creativity Level      | Deterministic              | Creative, probabilistic          |\n",
    "\n",
    "### Let's begin with text generation using GPT-2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "prompt = \"The future of artificial intelligence is\"\n",
    "outputs = generator(prompt, max_length=50, temperature=0.7, num_return_sequences=1)\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d3391",
   "metadata": {},
   "source": [
    "\n",
    "## Variational Autoencoders (VAE)\n",
    "\n",
    "VAEs learn to encode input data into a latent distribution and then reconstruct it. This allows generation of new samples from that distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0330a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, latent_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 400),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(400, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(400, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        mu, logvar = self.fc_mu(encoded), self.fc_logvar(encoded)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc8e4e",
   "metadata": {},
   "source": [
    "\n",
    "## Generative Adversarial Networks (GAN)\n",
    "\n",
    "GANs use a generator and discriminator in a minimax game to produce realistic samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size=100, output_size=784):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=784):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c11b6",
   "metadata": {},
   "source": [
    "\n",
    "## Decoding Strategies\n",
    "\n",
    "We control generative behavior using decoding strategies like:\n",
    "- Greedy Search\n",
    "- Top-k Sampling\n",
    "- Top-p (Nucleus) Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"The role of artificial intelligence in healthcare is\"\n",
    "\n",
    "print(\"Greedy decoding:\")\n",
    "print(generator(prompt, do_sample=False, max_length=50)[0]['generated_text'])\n",
    "\n",
    "print(\"\\nTop-k sampling:\")\n",
    "print(generator(prompt, do_sample=True, top_k=50, max_length=50)[0]['generated_text'])\n",
    "\n",
    "print(\"\\nTop-p sampling:\")\n",
    "print(generator(prompt, do_sample=True, top_p=0.9, max_length=50)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4147d",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation of Generated Text\n",
    "\n",
    "We use metrics like:\n",
    "- **BLEU**: N-gram overlap\n",
    "- **ROUGE**: Recall-oriented overlap\n",
    "- **BERTScore**: Semantic similarity using embeddings\n",
    "\n",
    "Example with BLEU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e52018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = [[\"this\", \"is\", \"a\", \"test\"]]\n",
    "candidate = [\"this\", \"is\", \"a\", \"trial\"]\n",
    "\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(f\"BLEU Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf7915",
   "metadata": {},
   "source": [
    "\n",
    "## Exercises\n",
    "\n",
    "1. Train a VAE on the MNIST dataset and visualize generated digits.\n",
    "2. Modify the GAN architecture and try generating digits from noise.\n",
    "3. Compare decoding strategies using different prompts and temperatures.\n",
    "4. Try calculating ROUGE or BERTScore on generated text.\n",
    "\n",
    "## References and Links\n",
    "\n",
    "- Hugging Face Transformers: https://huggingface.co/docs/transformers\n",
    "- PyTorch VAE Example: https://github.com/pytorch/examples/tree/main/vae\n",
    "- GAN Tutorial: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "- BLEU Score (NLTK): https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
