{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfa2625",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 4: Prompt Engineering and Generation\n",
    "\n",
    "This notebook explores prompt engineering techniques including:\n",
    "- Basic and advanced prompt types\n",
    "- Few-shot, zero-shot, and Chain-of-Thought prompting\n",
    "- Prompt templates and prompt tuning\n",
    "- Real-world applications in QA, summarization, and reasoning\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand prompt-based learning in LLMs\n",
    "- Design zero-shot, one-shot, and few-shot prompts\n",
    "- Implement Chain-of-Thought and Self-Consistency\n",
    "- Explore prompt templates using Hugging Face and LangChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856afc72",
   "metadata": {},
   "source": [
    "\n",
    "## Basic Prompting Techniques\n",
    "\n",
    "Prompting is about providing input in a format that steers the model’s output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "prompt = \"Translate English to French: How are you?\"\n",
    "print(generator(prompt, max_length=40)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00efad01",
   "metadata": {},
   "source": [
    "\n",
    "## Few-Shot Prompting\n",
    "\n",
    "Providing examples in the prompt helps LLMs generalize patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "few_shot_prompt = '''Translate English to French:\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Good night\n",
    "French: Bonne nuit\n",
    "\n",
    "English: Thank you\n",
    "French:'''\n",
    "\n",
    "print(generator(few_shot_prompt, max_length=50)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09676844",
   "metadata": {},
   "source": [
    "\n",
    "## Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "CoT improves reasoning by asking the model to “think step by step.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cot_prompt = \"If you have 5 apples and you eat 2, how many apples are left? Let's think step by step.\"\n",
    "print(generator(cot_prompt, max_length=60, do_sample=True, temperature=0.7)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff393fd",
   "metadata": {},
   "source": [
    "\n",
    "## Self-Consistency\n",
    "\n",
    "Generate multiple reasoning paths and pick the most consistent answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "responses = [generator(cot_prompt, max_length=60, do_sample=True, temperature=0.9)[0]['generated_text'] for _ in range(3)]\n",
    "for i, r in enumerate(responses):\n",
    "    print(f\"Response {i+1}:\\n{r}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995d49d",
   "metadata": {},
   "source": [
    "\n",
    "## Prompt Templates using LangChain\n",
    "\n",
    "LangChain supports structured templates and parameter substitution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5621110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"Write a poem about {topic}\")\n",
    "print(template.format(topic=\"the moon\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9093eed3",
   "metadata": {},
   "source": [
    "\n",
    "## Applications of Prompt Engineering\n",
    "\n",
    "- Summarization: \"Summarize this article in 3 bullet points.\"\n",
    "- QA: \"Answer the question based on the given context.\"\n",
    "- Code Generation: \"Write a Python function to compute factorial.\"\n",
    "- Classification: \"Classify the sentiment of this review.\"\n",
    "\n",
    "Prompting is task-flexible and aligns with few/zero-shot learning paradigms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3396641a",
   "metadata": {},
   "source": [
    "\n",
    "## Exercises\n",
    "\n",
    "1. Try one-shot prompting for translation or QA.\n",
    "2. Modify the Chain-of-Thought prompt to solve a math word problem.\n",
    "3. Generate 5 completions and apply majority voting (Self-Consistency).\n",
    "4. Create your own prompt template using LangChain.\n",
    "\n",
    "## References\n",
    "\n",
    "- Prompt Engineering Guide: https://github.com/dair-ai/Prompt-Engineering-Guide\n",
    "- LangChain Prompt Docs: https://docs.langchain.com/docs/components/prompts\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
