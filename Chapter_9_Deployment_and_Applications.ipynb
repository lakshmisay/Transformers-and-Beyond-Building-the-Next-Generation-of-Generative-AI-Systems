{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db6325d",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 9: Deployment and Real-World Applications\n",
    "\n",
    "This notebook focuses on:\n",
    "- How to package and deploy generative models\n",
    "- Real-world use cases and architecture\n",
    "- Creating an API using FastAPI\n",
    "- Dockerizing an LLM app for production\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand deployment workflows for GenAI apps\n",
    "- Serve LLMs through a FastAPI REST endpoint\n",
    "- Package and containerize with Docker\n",
    "- Monitor performance and handle scalability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef6680",
   "metadata": {},
   "source": [
    "\n",
    "## Real-World Applications of Generative AI\n",
    "\n",
    "- Virtual Assistants and Chatbots\n",
    "- Legal and Financial Document Summarization\n",
    "- Personalized Education Systems\n",
    "- Generative Code Assistants\n",
    "- Content Creation for Marketing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58da20",
   "metadata": {},
   "source": [
    "\n",
    "## FastAPI Endpoint for LLM\n",
    "\n",
    "We can wrap our LLM in a FastAPI service for easy REST integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aeb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastapi import FastAPI, Request\n",
    "from transformers import pipeline\n",
    "\n",
    "app = FastAPI()\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "async def generate(request: Request):\n",
    "    data = await request.json()\n",
    "    prompt = data.get(\"prompt\", \"\")\n",
    "    output = generator(prompt, max_length=50)[0][\"generated_text\"]\n",
    "    return {\"response\": output}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa0fcc",
   "metadata": {},
   "source": [
    "\n",
    "## Running the API\n",
    "\n",
    "Save the FastAPI code to `main.py`, then run:\n",
    "\n",
    "```bash\n",
    "uvicorn main:app --reload\n",
    "```\n",
    "\n",
    "Test using:\n",
    "\n",
    "```bash\n",
    "curl -X POST http://127.0.0.1:8000/generate -H \"Content-Type: application/json\" -d '{\"prompt\": \"Explain AI\"}'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e8bdd",
   "metadata": {},
   "source": [
    "\n",
    "## Dockerizing a GenAI Service\n",
    "\n",
    "Create a Dockerfile:\n",
    "\n",
    "```Dockerfile\n",
    "FROM python:3.10-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "Build and run:\n",
    "\n",
    "```bash\n",
    "docker build -t genai-api .\n",
    "docker run -p 8000:8000 genai-api\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aadea66",
   "metadata": {},
   "source": [
    "\n",
    "## Monitoring and Logging\n",
    "\n",
    "Use tools like:\n",
    "- Prometheus + Grafana for metrics\n",
    "- Loguru / logging module for logs\n",
    "- Streamlit for quick dashboards\n",
    "\n",
    "Tip: Log inference time, input length, error types, GPU memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa08fec",
   "metadata": {},
   "source": [
    "\n",
    "## Exercises\n",
    "\n",
    "1. Modify the FastAPI endpoint to add streaming response.\n",
    "2. Add OpenAPI documentation using FastAPI decorators.\n",
    "3. Dockerize a LangChain RAG application.\n",
    "4. Set up a logging system to monitor your app in real-time.\n",
    "\n",
    "## References\n",
    "\n",
    "- FastAPI Docs: https://fastapi.tiangolo.com\n",
    "- Docker: https://docs.docker.com\n",
    "- Hugging Face Inference: https://huggingface.co/docs/transformers/main_classes/pipelines\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
