{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37669b9f",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 10: AI Governance, Risk, and Compliance\n",
    "\n",
    "This notebook covers:\n",
    "- Key principles of Responsible AI\n",
    "- Regulatory frameworks and compliance\n",
    "- Detecting model drift and bias\n",
    "- Logging, auditability, and explainability tools\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand AI governance and ethical deployment\n",
    "- Implement basic bias detection and drift monitoring\n",
    "- Log model input/output for audit trails\n",
    "- Explore tools for explainability and compliance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f05aef",
   "metadata": {},
   "source": [
    "\n",
    "## Principles of Responsible AI\n",
    "\n",
    "- Fairness: Avoid discrimination and bias\n",
    "- Transparency: Be clear about how decisions are made\n",
    "- Accountability: Enable audit and traceability\n",
    "- Safety: Protect users and mitigate harm\n",
    "- Privacy: Ensure data protection and user control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d09aec0",
   "metadata": {},
   "source": [
    "\n",
    "## Detecting Bias with AIF360\n",
    "\n",
    "Use IBM's AIF360 library to audit fairness of models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "# Example: Mock dataset (use real data for production)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'age': [25, 45, 35, 50, 23],\n",
    "    'gender': ['F', 'M', 'F', 'M', 'F'],\n",
    "    'label': [1, 0, 1, 0, 1]\n",
    "})\n",
    "\n",
    "# Convert to BinaryLabelDataset\n",
    "dataset = BinaryLabelDataset(df=df, label_names=['label'], protected_attribute_names=['gender'])\n",
    "metric = BinaryLabelDatasetMetric(dataset, privileged_groups=[{'gender': 'M'}], unprivileged_groups=[{'gender': 'F'}])\n",
    "\n",
    "print(\"Disparate impact:\", metric.disparate_impact())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cba717",
   "metadata": {},
   "source": [
    "\n",
    "## Monitoring for Drift\n",
    "\n",
    "Track data and model behavior over time to detect concept drift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71cda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Mock original and incoming data distributions\n",
    "original = np.random.normal(0, 1, 1000)\n",
    "incoming = np.random.normal(0.5, 1, 1000)\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "stat, p_value = ks_2samp(original, incoming)\n",
    "\n",
    "print(\"Drift detected:\" if p_value < 0.05 else \"No significant drift.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6451419",
   "metadata": {},
   "source": [
    "\n",
    "## Logging and Auditing with Python\n",
    "\n",
    "Keep a detailed log of inputs, outputs, and metadata for compliance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21675aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='audit.log', level=logging.INFO)\n",
    "logging.info(\"Prompt: Translate 'hello' to French | Output: 'bonjour' | Timestamp: 2025-05-16 18:00\")\n",
    "print(\"Log written to audit.log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8373b430",
   "metadata": {},
   "source": [
    "\n",
    "## Explainability with SHAP (for tabular models)\n",
    "\n",
    "SHAP helps visualize feature contributions to a modelâ€™s decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "# Sample data\n",
    "X = np.random.rand(100, 5)\n",
    "y = np.random.randint(0, 2, size=100)\n",
    "\n",
    "model = xgb.XGBClassifier().fit(X, y)\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "shap.plots.beeswarm(shap_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23df42d",
   "metadata": {},
   "source": [
    "\n",
    "## Exercises\n",
    "\n",
    "1. Use AIF360 on a real dataset (e.g., COMPAS or Adult Income) to test for bias.\n",
    "2. Build a pipeline that monitors and logs every inference request.\n",
    "3. Visualize SHAP values for a classification model.\n",
    "4. Simulate concept drift and create an alert system.\n",
    "\n",
    "## References\n",
    "\n",
    "- AIF360: https://aif360.mybluemix.net\n",
    "- SHAP: https://github.com/slundberg/shap\n",
    "- DPDP, GDPR, AI Bill of Rights: Understand key compliance rules\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
